# Monolingual LLMs – Automatic Rubric Evaluation Framework

This repository contains a modular evaluation pipeline for assessing **linguistic clarity**, **scientific accuracy**, and **reference quality** of answers generated by LLMs for specific research questions (RQ1, RQ2, etc.).

The system processes model outputs, computes structured scores, and saves them as a consolidated JSON file.

## Repository Structure

```
monolingual_llms/
│
├── linguistic_clarity.py
├── scientific_accuracy.py
├── references_check.py
├── main_rubric.py
│
├
│── gpt-5.1(RQ1).txt
│── gpt-5.1(RQ2).txt
│── deepseek-R1(RQ1).txt
│── deepseek-R1(RQ2).txt
│
├── rubric_results_RQ1_RQ2.json
└── README.md
```

## Running the Evaluation

1. Fill the `ANSWER_FILES` dictionary in `main_rubric.py`
2. Run:

```
python main_rubric.py
```

3. Results are saved to `rubric_results_RQ1_RQ2.json`

## Debugging

Debug mode is ON by default inside all modules.  
Disable it by setting:

```
DEBUG = False
```

## Customization

- Modify jargon list  
- Change connector list  
- Add reference metadata  

## License

MIT License.
